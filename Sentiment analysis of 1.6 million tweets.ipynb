{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import nltk\n",
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from nltk.tokenize import TweetTokenizer"
      ],
      "metadata": {
        "id": "tRUYHwFXXOzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoEOzNuWKGUI",
        "outputId": "dac6285e-6548-4351-c1f1-08ce18d25db7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Google Colab setups\n",
        "# Import Google Colab libraries\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Set up\n",
        "auth.authenticate_user()\n",
        "google_authentication = GoogleAuth()\n",
        "google_authentication.credentials = GoogleCredentials.get_application_default()\n",
        "drive_access = GoogleDrive(google_authentication)\n",
        "\n",
        "dataset_file_shared_link = \"1bELRhCpbqx8WwV-WZJJgv8NMmEPZNLzr\" # shared link id to dataset file saved in google drive\n",
        "dataset_filename = \"training.300000.processed.noemoticon.csv\" # dataset file name\n",
        "access_file = drive_access.CreateFile({'id':dataset_file_shared_link})\n",
        "access_file.GetContentFile(dataset_filename)\n",
        "\n",
        "# THIS IS THE CODE AUTO SAVING FILES BY GOOGLE \n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the required NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqDRAw61wEws",
        "outputId": "0c5e8730-7d2f-4200-bc80-400749a9f66a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv('training.300000.processed.noemoticon.csv', \n",
        "                   encoding='latin-1', \n",
        "                   header=None, \n",
        "                   names=['sentiment', 'id', 'date', 'query', 'username', 'text'], \n",
        "                   error_bad_lines=False, skiprows=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyaZUjq1XSeF",
        "outputId": "becf7cdf-f30d-4da5-bc4e-5cdf36751d04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-2eca8ba1531e>:2: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  data = pd.read_csv('training.300000.processed.noemoticon.csv',\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the text\n",
        "\n",
        "# Reference variable for tweet tokenizer\n",
        "tweet_tokenizer = TweetTokenizer()\n",
        "\n",
        "# Text preprocessing function\n",
        "def preprocess_text(text):\n",
        "  text = text.lower()  # Convert text to lowercase\n",
        "  text = re.sub(r'@[A-Za-z0-9]+', '', text)  # Remove mentions in the text\n",
        "  text = re.sub(r'https?://[A-Za-z0-9./]+', '', text, flags=re.MULTILINE)  # Remove URLs in the text \n",
        "  text = re.sub(r'[^A-Za-z0-9]+', ' ', text)  # Remove special characters and numbers in the text \n",
        "  text = re.sub(r'[?\\$\\.\\!](>=<*&%)', ' ', text) # Remove special characters in the text \n",
        "  text = re.sub(r'\\d+', ' ', text).strip() # Remove extra spaces and remove whitespace from the start and at the end of the text\n",
        "  tokens = tweet_tokenizer.tokenize(text) # Tokenize the text through a tweet tokenizer\n",
        "  text = [WordNetLemmatizer().lemmatize(word) for word in tokens if word not in stopwords.words('english')]  # Lemmatize the text and remove stopwords\n",
        "  return ' '.join(text).strip() # Return preprocessed text\n",
        "\n",
        "data[\"text\"] = data[\"text\"].apply(preprocess_text) # Apply preprocessing function to the dataset\n",
        "\n",
        "# Save the cleaned data to a CSV file in the Google Drive folder\n",
        "data.to_csv('cleaned_data.csv', index=False)"
      ],
      "metadata": {
        "id": "OjSfk-6rXcS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets with text as independent variable, sentiment as dependent variable, and a random state of 42\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['text'], \n",
        "                                                    data['sentiment'], \n",
        "                                                    test_size=0.2, \n",
        "                                                    random_state=42)\n",
        "\n",
        "# Vectorize the text data using TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer() # Reference variable for tfidf vectorizer\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train) # Transform training data using a tfidf vectorizer\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test) # Transform test data using a tfidf vectorizer"
      ],
      "metadata": {
        "id": "bHScjtGAKU4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Naive Bayes\n",
        "naive_bayes_classifier = MultinomialNB() # Reference variable for Multinomial Naive Bayes model\n",
        "naive_bayes_classifier.fit(X_train_tfidf, y_train) # Fit the training data\n",
        "y_pred_NB = naive_bayes_classifier.predict(X_test_tfidf) # Multinomial Naive Bayes model prediction\n",
        "\n",
        "# Print Naive Bayes results\n",
        "print(\"Naive Bayes: \") # Print the title\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_NB)) # Print accuracy score of the Multinomial Naive Bayes model\n",
        "print(\"Precision:\", precision_score(y_test, y_pred_NB, average='weighted')) # Print precision score of the Multinomial Naive Bayes model\n",
        "print(\"Recall:\", recall_score(y_test, y_pred_NB, average='weighted')) # Print the recall score of the Multinomial Naive Bayes model\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_NB)) # Print the confusion matrix of the Multinomial Naive Bayes model with heading"
      ],
      "metadata": {
        "id": "RNdqd8XfuQWi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75ff5604-6b24-45f0-8d4d-33b24f517abf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes: \n",
            "Accuracy: 0.7558666666666667\n",
            "Precision: 0.7559988598339187\n",
            "Recall: 0.7558666666666667\n",
            "\n",
            "Confusion Matrix:\n",
            " [[22833  7017]\n",
            " [ 7631 22519]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Support Vector Machines (SVM)\n",
        "svm = SVC(kernel='linear', C=1) # Create SVM model with linear kernel and regularization parameter of 1\n",
        "svm.fit(X_train_tfidf, y_train) # Fit the training data\n",
        "y_pred_svm = svm.predict(X_test_tfidf) # SVM prediction\n",
        "\n",
        "# Print SVM results\n",
        "print(\"Support Vector Machines:\") # Print the title\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm)) # Print accuracy score of the SVM model\n",
        "print(\"Precision:\", precision_score(y_test, y_pred_svm, average='weighted')) # Print precision score of the SVM model\n",
        "print(\"Recall:\", recall_score(y_test, y_pred_svm, average='weighted')) # Print recall score of the SVM model\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_svm)) # Print the confusion matrix of the SVM model with heading"
      ],
      "metadata": {
        "id": "Iy38fhLQKYXB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d1f4e58-0e6d-4f89-e7de-c6ec436736ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Support Vector Machines:\n",
            "Accuracy: 0.7689\n",
            "Precision: 0.7692272003503053\n",
            "Recall: 0.7689\n",
            "\n",
            "Confusion Matrix:\n",
            " [[22361  7489]\n",
            " [ 6377 23773]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM\n",
        "# Prepare the data for LSTM\n",
        "max_fatures = 2000\n",
        "tokenizer = Tokenizer(max_fatures, split=' ') # Tokenize max features\n",
        "tokenizer.fit_on_texts(data['text'].values) # Fit text data into tokenizer\n",
        "X = tokenizer.texts_to_sequences(data['text'].values) # Convert into sequences\n",
        "X = pad_sequences(X, maxlen=28) # Pad the sequence with a maximum of 28 tokens\n",
        "Y = pd.get_dummies(data['sentiment']).values # Convert categorical variable to dummy variable\n",
        "\n",
        "# Split LSTM data into training and test sets, with a random state of 42\n",
        "X_train_lstm, X_test_lstm, y_train_lstm, y_test_lstm = train_test_split(X, Y, \n",
        "                                                                        test_size=0.2, \n",
        "                                                                        random_state=42)\n",
        "\n",
        "# LSTM model\n",
        "lstm_model = Sequential() # Create a sequential model\n",
        "lstm_model.add(Embedding(max_fatures, 128, input_length=X.shape[1])) # Add embedding layer to the model\n",
        "lstm_model.add(SpatialDropout1D(0.4)) # drop out 1D features\n",
        "lstm_model.add(LSTM(196, dropout=0.2, recurrent_dropout=0.2)) # Add LSTM layer with 196 units\n",
        "lstm_model.add(Dense(2, activation='softmax')) # Add dense layer with 2 units\n",
        "lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # Compile the model with loss, optimizer, and metrics\n",
        "print(lstm_model.summary()) # Print model summary\n",
        "\n",
        "# Train the LSTM model\n",
        "lstm_model.fit(X_train_lstm, y_train_lstm, epochs=7, batch_size=32, verbose=2)\n",
        "\n",
        "# Evaluate the LSTM model\n",
        "y_pred_lstm = lstm_model.predict(X_test_lstm)\n",
        "y_pred_lstm = np.argmax(y_pred_lstm, axis=1)\n",
        "y_test_lstm = np.argmax(y_test_lstm, axis=1)"
      ],
      "metadata": {
        "id": "-9MsW7YPKZoK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "506bd081-42f5-4959-8c80-1a758504c092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 28, 128)           256000    \n",
            "                                                                 \n",
            " spatial_dropout1d (SpatialD  (None, 28, 128)          0         \n",
            " ropout1D)                                                       \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 196)               254800    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 394       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 511,194\n",
            "Trainable params: 511,194\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/7\n",
            "7500/7500 - 691s - loss: 0.5106 - accuracy: 0.7458 - 691s/epoch - 92ms/step\n",
            "Epoch 2/7\n",
            "7500/7500 - 694s - loss: 0.4889 - accuracy: 0.7599 - 694s/epoch - 92ms/step\n",
            "Epoch 3/7\n",
            "7500/7500 - 692s - loss: 0.4801 - accuracy: 0.7656 - 692s/epoch - 92ms/step\n",
            "Epoch 4/7\n",
            "7500/7500 - 693s - loss: 0.4739 - accuracy: 0.7686 - 693s/epoch - 92ms/step\n",
            "Epoch 5/7\n",
            "7500/7500 - 692s - loss: 0.4693 - accuracy: 0.7726 - 692s/epoch - 92ms/step\n",
            "Epoch 6/7\n",
            "7500/7500 - 692s - loss: 0.4632 - accuracy: 0.7767 - 692s/epoch - 92ms/step\n",
            "Epoch 7/7\n",
            "7500/7500 - 691s - loss: 0.4583 - accuracy: 0.7789 - 691s/epoch - 92ms/step\n",
            "1875/1875 [==============================] - 31s 16ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print LTSM results\n",
        "print(\"LSTM:\") # Print title\n",
        "print(\"Accuracy:\", accuracy_score(y_test_lstm, y_pred_lstm)) # Print accuracy score of the LSTM model\n",
        "print(\"Precision:\", precision_score(y_test_lstm, y_pred_lstm, average='weighted')) # Print precision score of the LSTM model\n",
        "print(\"Recall:\", recall_score(y_test_lstm, y_pred_lstm, average='weighted')) # Print the recall score of the LSTM model\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test_lstm, y_pred_lstm)) # Print the confusion matrix of the LSTM model with heading"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpP0rmf7WbEi",
        "outputId": "da9b7e7d-61d0-4354-96ea-eb7fccc0aa4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM:\n",
            "Accuracy: 0.7628833333333334\n",
            "Precision: 0.7629909340658617\n",
            "Recall: 0.7628833333333334\n",
            "\n",
            "Confusion Matrix:\n",
            " [[23008  6842]\n",
            " [ 7385 22765]]\n"
          ]
        }
      ]
    }
  ]
}